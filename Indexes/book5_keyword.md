| keyword | description | page | 
| -----   | ----- | ----- |
| Perimeter security | has a major failing: it was not built with assume breach in mind, yet a compromise is inevitable. Inside access is not always benign. Modern attacks are inside out. A trusted system brings attacker in. Internal access is loosely regulated. Assets wont be 100% controlled. | 5.3 |
| Zero trust, Basic Princilbles | Network is always hostile: assume breach; Internal and external threats are always present.; Internal network does not equal trusted; Every device, user, and network flow must be proven.; Log and inspect all traffic. | 5.4 |
| Zero Trust Architecture | developed by Forrester's John Kindervag in 2010; **Data-centric focus** <br> **Basic principles of zero trust:**; Network is always hostile: assume breach; Internal and external threats are always present.; Internal network does not equal trusted; Every device, user, and network flow must be proven.; Log and inspect all traffic. | 5.4 |
| Network school of thought, ZT | doubled down on using network controls for security by creating smaller network segments and measuring trust of devices before network controls allow access to resources. While promising, this approach was highly complex and saw limited uptake outside a few bright spots like Googles BeyondCorp. | 5.5 | 
| Identity School of thought, ZT | Another approach, advocated by the Jericho Forum, pushed to move away from network security controls entirely with a ***de-perimeterzation approach***. This approach was largely beyond the reach of technology available at the time but planted important seeds for the Zero Trust of today. | 5.5 ||
| Zero Trust Tenets | **1. Network is hostile**<br> -Traffic must be authenticated.<br> -Traffic must be encrypted.  <br> **2. Least privilege must be enforced**.<br> -Trust must be factored into least privilege.<br> -Trust is no longer binary (yes or no).<br> -Access is granted per-session basis based by dynamic policy. <br> **3.** All data flows must be known and controlled. <br> **4.** All assets must be scanned, hardened, and rotated.   <br> **Trust Nothing Verify Everything** | 5.6 |
| Identity = User + Device + Context | Forresters original ZT research used the concept of a network agent for access.  In that model a network agent is a user and device combined.This new type of identity (user+device+context) is used to determine authorization. <br><br> User + corporate laptop = what access?<br> >User + personal laptop = what access?<br> User + corporate phone = what access? <br> Access to data is based on variable or dynamic trust | 5.7 |
| Identity management | goes a long way in tightening controls and limiting access to data. <br> The issue with identity management is that most solutions focus entirely on the user. User authentication, whether with username and passwords or multifactor authentication, is often attributed to the identity. Yet identity should be based on both the user and device being used. <br> The combination of the user and device equates to what the original zero trust model refers to as a network agent. Access to data should be controlled based on the combined identity of a network agent. | 5.7 |
|  Zero Trust, Purpose |     To understand and control how users, processes, and devices interact with data. | 5.7 |
|  Tuple, zero trust |  A combination of the user, device, and other security-relevant contextual information (e.g., location, time of day, previous behavior). Used to make an access decision. <br> Authentication: Explicit authentication of both the user and the device is required for a reliable tuple.  | 5.7|
| Zero Trust Decision Engine | ; Examines the tuple in the access request.; Compares it to the security policy for the requested data/resource.; Makes a risk-informed decision on whether to allow access. | 5.7 |
| Varible Trust | With a zero trust architecture, trust must be earned and can change dynamically. For example, a user accessing a PCI database needs enough trust to gain access. It is possible to quantify the trust requirements such as by giving user points for logging in with a username and password and using a known device and location. Yet access is not simply yes and no. | 5.8 | 
| Rotation, Trust over time | With zero trust, trust is earned or lost. One concept is that assets can lose trust simply due to time. The reasoning behind this is that the longer a machine has been in production, the more likely it is compromised or deviates from the baseline. This applies to more than systems; user, service, applications that utilize credentials and/or certificates. The longer these are in production, the more likely they are to be stolen and used. As a result, rotation is a necessary control within a zero trust architecture. | 5.9 |
| Remote Exploitation/Insider Threat, ZT Example | *SEE SLIDE:* a malicious cyber actor compromises a users device through an internet-based mobile code exploit. While a level of compromise occurs, damage is limited, and the time for defensive systems to detect and initiate appropriate mitigating responses is greatly reduced. | 5.1O |
| NIST SP 1800-35B |  Implementing a Zero Trust Architecture, builds up on NIST SP 800-207. This NIST Cybersecurity Practice Guide explains how 65 commercially available technologies can be integrated and used to build various ZTAs (see notes). TL/DR: no solution can provide full 100% ZT! | 5.11 |
| Policy Engine (PE) | The PE handles the ultimate decision to grant, deny, or revoke access to a resource for a given subject. The PE calculates the trust scores/confidence levels and ultimate access decisions based on enterprise policy and information from supporting components. The PE executes its trust algorithm to evaluate each resource request it receives.  | 5.11 |
| Policy Administrator (PA) | The PA executes the PEs policy decision by sending commands to the PEP to establish and terminate the communications path between the subject and the resource. It generates any session-specific authentication and authorization token; or credential used by the subject to access the enterprise resource. When combined, the functions of the PE and PA comprise a PDP. The PDP is where the decision as to whether or not to permit a subject to access a resource is made. These are essentially identity management solutions, access and credential management technologies supporting SSO and MFA, federated identity solutions, and identity governance solutions like Okta, Azure AD with Conditional Access. | 5.11 |
| Policy Enforcement Point (PEP) | The PEP guards the trust zone that hosts one or more enterprise resources. It handles enabling, monitoring, and eventually terminating connections between subjects and enterprise resources. It operates based on commands that it receives from the PA | 5.11 |
| Network-level PEPs |  such as: routers, switches, firewalls, reverse proxies, web application firewalls, software-defined networking, etc. Typically, network-level PEPs, such as routers, switches, and firewalls, do not integrate directly with Identity, credential and access management (ICAM) solutions but some are identity aware. <br> endpoint protection solutions in general do not typically integrate directly with ICAM solutions. However, some of the endpoint protection solutions considered for use in the builds have out-of-the-box integrations with the MDM/UEM solutions used, which provide the endpoint protection solutions with an indirect integration with the ICAM solutions. | 5.11 |
| Unified endpoint management (UEM) tools |  Tools for Policy Enforcement Point (PEP): The PEP guards the trust zone that hosts one or more enterprise resources. | 5.11 | 
| Endpoint ACLs via DLP | host-based firewalls, data rights management or any other technology connections between subjects and enterprise resources, Network Pep | 5.11 | 
| Zero Trust Maturity Model | is one of many roadmaps that agencies can reference as they transition towards a zero trust architecture. The maturity model aims to assist agencies in the development of zero trust strategies and implementation plans and to present ways in which various CISA services can support zero trust solutions across agencies. |  5.13 |
| zero trust model implementation | will be a journey through multiple stages for most organizations, not a one-step process, one that will vary organization to organization based on your business priorities, budget, personnel, regulatory environment and risk appetite among other things. | 5.13 |
| OMB, Office of Public Mgmt | shared some of their priorities in a public document that details their ZT journey: - Removing implicit trust of connections between systems, starting with HTTP and DNS - Deprecate decryption in transit with long-lived keys to favor context-aware decisions about visibility vs attack surface - Shifting away from traditional intranet/VPN model - Moving authentication to the application layer and use of phishing-resistant authentication methods - Treating everything as internet-accessible - Big emphasis on first/third-party testing (see new SEC568: Combating Supply Chain Attacks with Product Security Testing) | 5.15 |
| Zero-trust mindset | includes the importance of being able to develop a holistic picture of the major areas of risk of an organization, while at the same time being prepared to zero-in on the risks introduced by a particular device or a specific product and answer a key question: what is the risk to introduce this product? How will it increase my attack surface? How can I mitigate those risks with actionable defensive countermeasures | 5.15 |
| CIS Controls (version 8) | This new version refined previous recommendations. It adjusted prioritizations of some Controls and Safeguards based on expert consensus and validated by current threats to have the most impact in reducing risk.Within each of the 18 Controls, there is a set of Safeguards. The Safeguards comprise the more fine-grained recommendations to address the associated threats for that Control. Each Safeguard is categorized into one of three Implementation Groups (IGs), providing the prioritized recommendations that span the 18 CIS Controls. Controls v8 supports a zero trust architecture, while also aligning to the recommendations for built-in security, pervasive encryption, allow-list functionality, and supply chain security risk reduction called out specifically in the Cybersecurity Executive Order published in May 2021 | 5.17 |
| ZT Review | Least privilege should be founded on zero trust.; All access should be authenticated and verified.; Trust should be earned and dynamically adapt.; Know thy network is a must.Implementations should start with the basics.; Securing systems with critical data; Server to server communication (easier to start with); Always prioritize and balance based on high-value assets and security risk | 5.18 |
| Identity as a Perimeter | Probably one of the most important transformations for any organization that wants to implement ZT.   It requires a short and long-term approach to managing: Identity, Authentication, Authorization:  Across people, devices, networks, workloads and data. <br> Identity/Authentication/Authorization: People, Devices, Networks, Workloads, Data | 5.2O | 
| Identity Management, ZT | Ensuring that information is accessed by the right users, at the right time, and for the right purposes is paramount. Doing this requires a strong way to verify the users identity when they attempt to access systems. This often requires consolidating the means of authenticating as much as possible and practicable. <br> Using centrally managed systems to provide enterprise identity and access management services reduces the burden on staff to manage individual accounts and credentials. It also improves knowledge of user activities, enabling better detection of anomalous behavior, allowing to more uniformly enforce security policies that limit access, as well as quickly detect and take action against anomalous behavior when needed. <br> A well-designed enterprise identity management system performs these functions and integrate into as many applications as possible. They should also be capable of supporting human authentication through non-graphical user interfaces, such as scripts and command line tools. <br> <br> For most enterprises, the **starting point is a Windows Server AD being replicated to the cloud Azure AD (now Entra ID)** using Azure AD Connect or the new Azure AD Connect cloud sync in a sort of hybrid identity. <br> *These solutions create a common user identity for authentication and authorization to all resources, regardless of location.* | 5.21 |
| Azure AD Connect cloud sync |  is a new approach for the synchronization of users, groups, and contacts to Entra ID. It accomplishes this by using a lightweight provisioning agent instead of the old school Azure AD Connect application that is based on MIM. Cloud Sync is not feature complete when compared with AAD Connect, namely it is missing the ability to sync devices, custom attributes, and perform device/group writeback. It does however support Password Hash Sync. | 5.21 |
| Password hash sync (PHS) | is a sign-on method used to accomplish hybrid identity. AAD connect syncs a hash of the hash, of a users password from on-premises AD to Azure AD. Password Hash Sync also enables leaked credential detection for these hybrid accounts. If username/password pairs are found in public breaches, the associated account is moved to high risk and conditional access policies can kick off to take action on the user. | 5.21 | 
| Identity Federation | Allows users to access resources across multiple domains or organizations with a single set of credentials...e.g., Dropbox, Salesforce, ServiceNow | 5.23 |
| Entra ID auth | supports provisioning users into applications hosted on-premises or in a virtual machine, via protocols like SCIM, LDAP, SQL, REST, SOAP or just simply PowerShell. | 5.23 |
| System for Cross-domain Identity Management (SCIM) | specification provides a common user schema to help users move into, out of, and around apps. SCIM is becoming the de facto standard for provisioning and, when used with federation standards like Security Assertions Markup Language (SAML) or OpenID Connect (OIDC), provides administrators an end-to-end standards-based solution for access management. | 5.23 |
| Security Assertion Markup Language,|  an XML standard for exchanging authentication and authorization data between applications.
| SAML SSO |  To implement SSO with SAML, two entities are involved, an identity provider and a service provider. The IdP is responsible for authenticating users and providing them with a SAML assertion, which is a signed XML document that contains information about the user's identity and attributes, while the service provider is the application that the user is trying to access. The SP trusts the IdP to authenticate users and will grant access to the application based on the information contained in the SAML assertion. A SAML assertion (also known as SAML tokens) carries sets of claims made by the IdP about the principal (user). It contains authentication information, attributes, and authorization decision statements. | 5.25 |
| Entra ID Attack Vector | Example shows how a rouge DHCP server, ARP Spoofing, or IPv6 RA can trick server into being the gateway for microsoft login and have MiTM Certificate trust by ADCS to recieve clear text creds | 5.27-29 |
| Entra ID, Attack Mitigations |   On-prem is still in most cases the weakest link. <br> Layered defense is vital, including: - Endpoint security and secure workstations 1, 2 - Network segregation and monitoring - Hardening against L2 attacks (e.g., ARP spoofing, DHCP, IPv6 RA) increases the attackers cost. <br> Privileged Access Management - Implement PAM solutions to enforce secure administrative access to the AD Connect server. - Monitor for abnormal activity. <br> Restrict access to certificate templates that allow server authentication and monitor enrollment. | 5.31 |
| Path of Least Resistance | Attackers are lazy! - You need to continue working on securing your on-prem identity management systems, implementing less implicit trust as these are often the weakest link, and the target of attackers. - This includes: User passwords (yes, we still have those),  Service accounts | 5.32 |
| NIST 800-63B | NIST 800-63B is on Digital Identity Guidelines: Authentication and Lifecycle Management. NIST clearly states password rotation is not recommended. "Verifiers SHOULD NOT require memorized secrets to be changed arbitrarily (e.g., periodically). However, verifiers SHALL force a change if there is evidence of compromise of the authenticator."1 Based on studies that show password rotation increases the likelihood of poor passwords | 5.33 |
| Password Policies | A major concern with password rotation is that end users who are forced to change passwords once a month or even once every couple of months end up choosing easier to guess passwords or permutations of previous passwords. This greatly increases the likelihood that an adversary can guess passwords or re-obtain previously compromised credentials. The results of this are primarily due to having poor password policies. | 5.34 |
| Fine-grained password policies | allow password policies to be set per user or group so long as that user or group is a global object in Active Directory. Server 2012 and Windows 8 and later can set a fine-grained password policy via the Active Directory Administrative Center. In Active Directory, you can manage fine-grained password policies (PSOs) using Powershell as well, but the Active Directory PowerShell module must be installed on the computer in order to do so. | 5.34 |
| Third-Party Password Policy Management | Microsoft's password policy allows weak passwords. Winter2023! is susceptible to cracking and guessin; But meets complexity requirements <br> Third-party solutions provide granular policy requirements; Cannot contain dictionary term; Disallow characters at beginning or end of passwor; Present GUI breakdown of rule; Disallow passwords using common permutationsLinux pluggable authentication module (PAM) has granular support <br> <br> Some third-party solutions allow the installation of a client-side component that replaces the default password change GUI to include the password policy rules.| 5.35 |
| passfilt.dll. | This DLL handles password policy enforcement. When a third-party solution is used, then password policies become significantly more granular. Extra capabilities include but are not limited to the ability to block passwords that are an exact or partial match to a dictionary list, that begin with or end with certain characters, such as special characters or numbers, or that use common permutations that password crackers automatically attempt. | 5.35 |
| Password policy general rule | the more controls enabled in a password policy, the more training end users should have received. Also, it is important to explain why and notify users that it is to protect them and that they should follow the same rules in their personal life.  | 5.35 |
| Entra Password Protection | Users often create passwords that leverage common words or phrases that are generally aligned to their workplace, sports team, celebrity, or season/year...ect... <br> - These passwords are easy to guess and susceptible to brute force and password spray attacks. Entra Password Protection provides a global and custom banned password list for that purpose that gets applied to all Entra users by default. A password change request fails if there's a match found in the banned passwords list.  | 5.36 | 
| Banned password list, Custom | Used with Entra Password protection; focuses on organizational-specific terms can also be created, containing, for example: - Brand names - Product names - Locations, such as company headquarters - Company-specific internal terms - Abbreviations that have specific company meaning | 5.36 |
| Password Auditing | Passwords should be evaluated for weaknesses. <br> - Consider doing it before the adversary does.Possible to intentionally dump hashes and test them <br> - Get-bADpasswords can automate the process <br> - Hashes can be pulled from volume shadow copy <br> - Linux hashes in /etc/passwd and /etc/shadow <br> Hashes can be sent to system with GPUs: - Low-cost solution for password auditing | 5.37 |
| rainbow table | is the result of pre-computed password hashes saved in a database so that they can be quickly used to look up cleartext passwords.  The reason a strong password policy is necessary is to prevent passwords that are easy to guess or crack | 5.37 |
| Password cracking Solutions | If using to do auditing, it should be hardened and heavily segmented. If the system ever were to be compromised, an adversary would have access to company-wide password hashes. Also, the system should use graphics cards for password cracking. The math computations performed by a graphics card are thousands of times faster than CPUs, and so a system with one or more graphics card is more efficient. Lastly, you should have permission to implement this solution. Some countries or legal departments may object to the use of a password auditing solution | 5.37 |
| Service accounts | often are purpose-built for a specific application. Because of this service account, passwords often are never changed for fear of breaking the application. This can lead to problems, as service accounts often have elevated privileges and are not locked down or monitored appropriately.  ROTATE THEM | 5.38 |
| Local Admin Account | is recommended to be disabled, but organizations commonly enable it for troubleshooting purposes. Administrator account password is often the same across an organization. This typically is because the system was deployed using a gold image or master image, such as using Microsoft SCCM to deploy workstation images. | 5.38 |
| LAPS - Local Administrator Password Solution |  is a free tool capability from Microsoft. <br> - Newer version is now built into Windows since April 2023 <br> - Automatically rotates local admin password <br> - Can back up passwords to Entra ID Active Directory, encrypt passwords in AD and store password history in case you need to log back into restored backup imagesLAPS is centrally controlled via Active Directory but can also now be managed via a Configuration Service Provider (CSP) to administer Entra ID policies, and via Intune. | 5.39 |
| LAPS | part of the OS capabilities since the 2023-04 Cumulative Update for Windows update or later installed, for the following Windows editions:<br> - Windows 11 Pro, EDU, and Enterprise<br> - Windows 10 Pro, EDU, and Enterprise<br> - Windows Server 2022 and Windows Server Core 2022<br> - Windows Server 2019 <br> - Windows LAPS inherits many design concepts from the older Microsoft LAPS product which has been rebranded as Legacy LAPS. Legacy LAPS. A key difference is that Windows LAPS is an entirely separate implementation that is native to Windows. Windows LAPS adds many features that arent available in Legacy LAPS. <br> - The latest iteration can back up passwords to Azure Active Directory, encrypt passwords in Windows Server Active Directory, and store your password history. <br> The new LAPS also provides support for Microsoft Intune including the ability to rotate passwords. With this policy you can have devices automatically rotate the local admin account passwords on a schedule. You can also use the Intune admin center to manually rotate the password for a device as a device action. | 5.39 |
| LAPS Group Policy | Windows LAPS includes a new Group Policy Object that you can use to administer policy settings on Active Directory domain-joined devices. To access the Windows LAPS Group Policy, in Group Policy Management Editor, go to Computer Configuration > Administrative Templates > System > LAPSThe template for this new Group Policy object is installed as part of Windows at %windir%\PolicyDefinitions\LAPS.admx.| 5.4o |
| MSA, managed service account  | is a type of domain account created and managed by the domain controller. It is assigned to a single member computer for use running a service. An MSA has the ability to register a Service Principal Name (SPN) within Active Directory when given read and write servicePrincipalName permissions. An MSA is named with a $ suffix, for example `DOMAIN\ACCOUNTNAME\$ | 5.41 |
| gMSA, group-managed service account (gMSA) | is an MSA for multiple servers. Windows manages a service account for services running on a group of servers. Active Directory automatically updates the group-managed service account password without restarting services. A gMSA solves many of the issues associated with MSAs. For example, a gMSA can be used across multiple hosts. This capability alone enables advanced use cases such as with clustering or load-balanced farms. Also, gMSAs can be used with scheduled tasks and mainstream applications such as Microsoft SQL 2014 or later. Also, gMSAs work with scheduled tasks. <br> <br> The use of gMSA requires an AD schema of Server 2012 or higher and a domain controller with the Microsoft Key Distribution Service enabled.| 5.41 |
| gMSA, group-managed service account creation |  to create, a KDS root key must first be created on a domain controller. To do this, the command Add-KdsRootKey needs to be run within PowerShell. After this command, you must wait 10 hours for the key to be replicated to all domain controllers. Then PowerShell can be used to create a managed service account and then PowerShell can be used on each host the managed service account is going to be used on. <br> The use of gMSA requires an AD schema of Server 2012 or higher and a domain controller with the Microsoft Key Distribution Service enabled.| 5.41 |
| Securing Traffic, ZT | If the network is not trusted, all network traffic MUST be:; **Authenticate**: Prove user/device is legitimate; <br> **Encrypted**: Cryptographically prove source and destination while protecting confidentiality <br> Encryption cannot be perimeter-based.; Requires encryption at either device or application; Endpoints configured to drop anything not encrypted| 5.44 |
| Full encryption enforcement | under zero trust means *all traffic must first be authenticated and encrypted*. Anything else must be dropped.  | 5.44 |
| network transmission secure methods |- TLS: Transport layer security<br> - IPsec: Kernel-level authentication and encryption<br> - 802.1X: Port-based network access control<br> - Single packet authorization (SPA) <br> **TLS and IPsec provide authentication and encryption.**:- 802.1X and SPA only provide authentication. - Zero trust mandates end-to-end encryption. | 5.45 | 
| one-way trusts, Zero Trust Model Change | A connection to a website using HTTPS typically involves a client verifying that a server is who it claims to be. Yet TLS can also be used to verify a client is who they claim to be. While mutual authentication is supported, it may not be practical for external facing applications that are from unknown clients. | 5.46 |
| Mutual authentication, ZT Model Change | Client connections should only be from authorized systems. Therefore, why would a connection be allowed to or from untrusted clients? In this respect, systems can be configured to use mutual authentication. <br> Provides enhanced encryption, also minimizes the attack surface. <br>  If a client cannot interact with a web server because it cannot pass a client certificate check, then it is significantly less likely to be able to exploit the web server successfully. | 5.46 |
| Mutual TLS (mTLS) | 1. The client hello contains the TLS versions, cipher suites supported, client's order of preference, a random byte used for subsequent computations, and session-specific data.<br> 2.The server sends the client its TLS versions and cipher suites supported compared to the client's list, a random byte, the server's certificate, and a client certificate request.<br> 3.The client verifies the server's certificate is valid.<br> 4.The client calculates pre-master key and encrypts it with server's public key and uses the client's private key to encrypt additional data known by both the server and client. The client also sends the client's digital signature to the server in this step.<br> 5.The server verifies client's certificate. <br> - Between step 5 and 6, both the client and server use the pre-master key to generate session keys. These keys are symmetric.<br> 6.The client sends a message to the server that future communication will be encrypted with the session key. The client also sends a separate message that the client handshake is complete<br> 7.The server sends a message to the client that future communication will be encrypted with the session key. The server also sends a separate message that the server handshake is complete. <br> The client certificate request in step two includes a list of supported certificate types and the distinguished names of supported certificate authorities. | 5.47 |
| ssl_client_certificate | Nginx setting, the certificate referenced is actually the public key of an authorized certificate authority. This certificate authority is what is used to verify a client's certificate. | 5.48 |
| One-to-one mappings, Client Cert, Mutual Auth | each client certificate is mapped to a user account. | 5.48 |
| May-to-one mappings, Client Cert, Mutual Auth | multiple certificates to a user account.  | 5.48 |
| mutual authentication IIS Client Certs |  one simply has to enable SSL settings and then click on Require under client certificates. | 5.48 |
| mutual authentication, Apache or NGINX Client Certs | the configuration file needs to be modified to force client verification and to specify which certificate authority the client will be verified against.While the NGINX configuration has a setting called ssl_client_certificate, the certificate referenced is actually the public key of an authorized certificate authority. This certificate authority is what is used to verify a client's certificate. The main issue with deploying mutual authentication is not configuring applications but instead getting certificates on both clients and servers. | 5.48 | 
| IIS Client Certs |  one simply has to enable SSL settings and then click on Require under client certificates. | 5.48 |
| Apache or NGINX Client Certs | the configuration file needs to be modified to force client verification and to specify which certificate authority the client will be verified against.While the NGINX configuration has a setting called ssl_client_certificate, the certificate referenced is actually the public key of an authorized certificate authority. This certificate authority is what is used to verify a client's certificate. The main issue with deploying mutual authentication is not configuring applications but instead getting certificates on both clients and servers. | 5.48 | 
| mTLS for API Security | mTLS is often used in business-to-business (B2B) applications and microservices to authenticate access to APIs.<br> Combined with API gateways and mTLS cert offloading, it can add an authentication layer to serverless and modern API based apps.<br> Mutual TLS authentications main downside is the difficulty in managing the certificate lifecycle. | 5.49 | 
| mTLS - Mutual TLS authentications |  main downside is the difficulty in managing the certificate lifecycle. | 5.49 | 
| Mutual TLS (mTLS) | can also be used to authenticate client applications to the application programming interfaces (APIs) of a website. This is often used in mobile applications, client applications or third-party vendor applications calling our APIs.  | 5.49 |
| OAuth 2.o | often used to authenticate mobile devices by storing a JSON Web Token (JWT) on the device. Using the JWT token is just as secure as using two-way TLS/SSL. With mutual TLS is especially common to find that every mobile device running a mobile application has the same certificate. If that certificate is ever compromised, all mobile devices that downloaded the app will need to be updated with refreshed certificates.  On the other side, mutual TLS provides an extra layer of security when the information is sensitive enough to require user and device authentication.  | 5.49 |
| Hashicorp Vault | can be used as an x509 mgmt solution | 5.49 |
| Public Key Infrastructure (PKI) | Public key infrastructure is designed to support cryptographic trust and allow encryption via asymmetric and symmetric keys. The problem is PKI is complex and difficult to manage. Even with PKI being out for a long period of time, it still is difficult. Fortunately, most organizations own Windows Server licenses. What they do not know is that because of this license, they can deploy a Windows PKI system. Windows PKI, in turn, provides an easier PKI implementation that supports automatic certification issuance to Windows systems and can integrate with other systems such as Cisco or Linux. | 5.5O |
| Root CA, PKI |  Self-signed CA and most trusted CA, highly recommended for only issuing or renewing other cert authorities | 5.51 |
| Intermediate CA, PKI |  Down-level CA usually controlling subordinate CAs, allows granular control, such as restrictions of Sub CAs and certs  | 5.51 |
| Subordinate CA, PKI |  Certificate issuing CA, just certs | 5.51 |
| Standalone CA | Common to small shops; Manual certificate creation; Common for Linux shops; Recommended for root or intermediate CAs; Should be run off-line   Or out-of-band | 5.52 |
| Enterprise CA  | Windows-specific deployment; Requires domain membership; Allows automatic enrollment; Can be used for smart cards; Requires AD access (never offline); Contains templates; Active Directory Certificate Services PKI 2019 can be deployed to Azure, AWS or GCP (see notes) | 5.52 |
| Certificate Automatic Enrollment | Windows PKI allows supports of automatic enrollment of:  - Device Certificates, Associated with device activities; <br> - User Certificates: Associated with user activitiesCapabilities and integration:; 802.1X; Code signing; TLS; Smart cards; IPsec; LDAPS; Remote Desktop Protocol; PowerShell remoting | 5.53 |
| Certificate automatic enrollment settings |  are controlled under the following GPO locations: <br> - *Computer Configuration -> Security Settings -> Public Key Policies -> Certificate Services Client - Auto-Enrollment Properties* <br> - *User Configuration -> Security Settings -> Public Key Policies -> Certificate Services Client - Auto-Enrollment Properties* <br> - *Computer Configuration -> Security Settings -> Public Key Policies -> Trusted Root Certificate Authorities* | 5.53 |
| SSL/TLS | operates at the transport layer. Where this comes into play is that an application must be configured to use and accept TLS as part of its supported transport mechanisms. The most common example is the application of HTTP. HTTP is often paired with TLS to form HTTPS. | 5.54 |
| IPsec | baked into the kernel and is processed by the internet layer of communication. This allows IPsec to be used regardless of application awareness or without requiring the use of TCP or UDP. Because of this, IPsec is highly flexible and an amazing option for adding authentication and encryption support | 5.54 | 
| Domain isolation | is the ability to prevent non-domain joined systems from accessing a Windows environment. Domain isolation uses IPsec built-in to Windows to authenticate, and optionally encrypt traffic. <br> mitigates MiTM, Lowers Sever Exploitation Risks | 5.55 |
| Windows IPsec | Deploying IPsec in a Windows environment is controlled with either PowerShell scripts or group policy, as IPsec is integrated into Windows Firewall. <br> - The first recommended step is to change the default IPsec settings.  IPsec connections fall into multiple phases and use mutual authentication similar to how a VPN is supposed to work. | 5.56 | 
| Phase 1 main mode, windows IPsec | default is to use *SHA-1 for integrity and either AES-CBC-128 or 3DES for encryption*. <br>  - The key exchange algorithm is set to Diffie Hellman Group 2, which uses a 1024-bit prime number. <br> - The default allows for wide support of devices and operating systems. <br> - Windows Vista or later, main mode can be changed to SHA-384 for integrity, to AES-CBC-256 for encryption, and changed to use Elliptic Curve Diffie Hellman P-384. <br> - Elliptic Curve is more secure than Diffie Hellman, even though it has a smaller bit size. | 5.56 |
| Elliptic Curve Diffie Hellman P-384 |  Elliptic Curve is more secure than Diffie Hellman, even though it has a smaller bit size. | 5.56 |
| Phase 2 quick mode, Windows IPsec | can be set to provide data integrity only using AH or provide data integrity and encryption via ESP or ESP and AH. <br> - Because ESP can traverse NAT resolution and a zero trust architecture mandates encryption, it is recommended to check **"Require encryption for all connection security rules that use these settings."** <br> Defaults for phase 2 quick mode allow authentication without encryption and use SHA1 with optional AES-128 or 3DES encryption.<br> - Windows Vista or later, quick mode can be changed to use a stronger encryption algorithm such as AES-GCM 256 and a stronger integrity algorithm such as AES-GMAC 256. Galois Counter Mode (GCM) and Galois Message Authentication Code (GMAC) require Vista systems to be service pack 1 or later. | 5.56 |
| Authentication method, Windows Ipsec |  Windows defaults to Kerberos computer authentication, which is a strong default setting. It only authorizes domain-joined systems this way, and Kerberos is a strong authentication protocol. <br> - Alternative options are to use certificates for users or computers, Kerberos for user authentication, a pre-shared key, or in later operating systems, NTLM version 2 for users or computers or a health certificate from Microsoft Network Access Protection. <br> - IPsec authentication can require both user and computer authentication, or both can be optional, or one can be optional. Having a computer and user authentication is necessary if Windows firewall rules may require authentication against computers and/or users. | 5.56 |
| Windows IPsec | IPsec integration is part of the Windows Firewall.<br> Change IPsec default options (recommended); Default does not mandate encryption for ESP<br> Requires connection security rules<br> Granular control via firewall rules | 5.56 |
| Single Packet Authorization (SPA) | Requires software on both the source and destination hosts; SPA involves blocking connections by default. -Connecting system must first send authentication packet. -Effectively a next-generation port knocking solution, including in cloud environments; <br> **SPA uses asymmetric encryption and HMAC**. -Packet is non-replayable due to HMAC and random data. -SPA includes request to authorize port or program. <br> Not a new technology, but  not widely used / not proven as a mature solution. SPA uses a single network packet to authenticate to an endpoint before gaining traditional access. Again, the focus is on authentication only | 5.58-59 | 
| NAC | been around for a long time and had one purpose: authenticate devices before they can talk on the network. This does not offer network encryption of traffic, but it is still significantly better to limit who can be on the network via authentication than to simply let anyone plug in and have access. | 5.58 |
| fwknop | opensource SPA, uses asymmetric keys and an HMAC to transmit a single packet that authenticates a device securely. This packet is composed of the following message composition:<br> 16 bytes of random data; local username; local timestamp; fwknop version; mode (access or command); desired access (or command string); MD5 sum <br> <br> - When the packet is received, the host decrypts the data and authenticates the packet. Within the packet is included what the source client wishes to access, whether it is a port or a program. If the receiving host authorizes the request, then subsequent requests from the client will be allowed.| 5.59 |
| Host-Based Firewall | Host-based firewalls like Windows Defender Firewall and Linux iptables provide endpoint-level network restrictions. These firewalls often come in commercial flavors that either integrate with the native operating system firewalls via built-in APIs or provide their third-party capabilities. <br> - A firewall on an endpoint is capable of more granular control than a network-based firewall <br> - the endpoint should be the ultimate deciding factor on whether or not a connection is allowed. <br> - can allow or deny based on executables as well as network ports and IP addresses.  | 5.64 |
| inbound-deny policy | to implement, you first must authorize all ports or executables. The ports and executables necessary to allow a connection exist in Windows firewall logs. Using scripts or central log collection helps sift through these logs and quickly identifies ports and executables to allow. | 5.65 |
| host-based firewall executables | lock down by execuatubles may be preferable to ports. By allowing access to authorized applications, ports will only be reachable when that executable is running. This prevents unauthorized applications from successfully listening on new ports. Regardless, allowing ports or executables is only a first step. Next, these ports and executables need to be locked down to specific hosts or subnets. | 5.65 |
| Outbound Access | Windows and Linux have thousands of binaries per system.<br> -Yet less than a hundred are likely to reach out.<br> -Only authorized binaries should make connections.<br> -Should limit authorized applications to their expected use cases. <br> **SMB** is necessary but should never happen to internet. <br> **powershell.exe** should be used for scripting but may not need outbound access at all. <br> Limiting CustomApp1 to specific hosts/networks helps prevent it from being used as an attack vector upon compromise.| 5.66 |
| Firewall Logging | Host-based firewalls provide a gold mine of information.; Monitoring provides the capabilities to implement granular rules.; Blocked events point to unauthorized connections. <br> -Logs operationalize endpoints as intrusion detection points.; Provides notification of unauthorized inbound and outbound connections; Allows for early detection and response <br> = Network firewalls can provide high-level central filtering.  Endpoint firewalls provide granular filtering. | 5.67 |
| Attack Surface Reduction, Microsoft | is a set of additional protections in Microsoft Defender Antivirus that can be turned on to log or intercept (block) some common attack scenarios.<br> - Such software behaviors are sometimes seen in legitimate applications. <br> - ASR can be bypassed but adds an additional layer of protection. | 5.68 |
| ASR Recomended policies |  <br> - Block Office communication apps from creating child processes (set to Enable) <br> - Block Adobe Reader from creating child processes (set to Enable) <br> - Block Office applications from injecting code into other processes (set to Block) <br> - Block Office applications creating executable content (set to Block) <br> - Block JavaScript or VBScript from launching downloaded executable content (set to Block) <br> - Enable network protection (set to Enable) <br> - Block untrusted and unsigned processes that run from USB (set to Block) <br> - Block credential stealing from the Windows local security authority subsystem (lsass.exe) (set to Enable) <br> - Block executable content downloads from email and webmail clients (set to Block) <br> - Block Win32 API calls from Office macro (set to Block) <br> - Block execution of potentially obfuscated scripts (js/vbs/ps) (set to Block) <br> - Block all Office applications from creating child processes (set to Block) <br> <br> You can also deploy these using the EndPoint protection configuration policies for Intune, and manage them through GPO and, of course, PowerShell.  | 5.68 |
| ASR rules | target certain software behaviors, such as:; Launching executable files and scripts that attempt to download or run files; Running obfuscated or otherwise suspicious scripts; Performing behaviors that apps don't usually initiate during normal day-to-day work | 5.68 |
| CIS Control 1 | Inventory of Authorized and Unauthorized Devices; <br> Has always been highest priority control <br> Step 1 is to inventory all devices; Step 2 is to only allow authorized devices on the network. | 5.71 |
| NAC | CIS Control 1- Inventory of Authorized and Unauthorized Devices: Has always been highest priority control <br> - Step 1 is to inventory all devices.<br> - Step 2 is to only allow authorized devices on the network.NAC provides real-time enforcement of network access.<br> - Fundamentally designed to perform both steps.<br> - Also, can change access based on variable conditions | 5.71 |
| NAC Practical | 1. Initial Connect <br>  2. Auth via Radious + Mac or cert, <br> 3 Vlan ENtry, <br> <br> UNAUTH VLAN if it didnt meat all 1-3 reqs... :  <br>4. DHCP Request on UnAuth Vlan <br> 5. DHCP Repsonse NAC=Gatway,NAC=DNS, Optional, Fingerprinting <br> 6. Client gets captive portal <br> <br> Simply because a device gets placed on an unauthorized VLAN does not mean it is game over. <br> - Just means Device failed 802.1X authentication and that it is up to a NAC solution to provide alternative controls. <br> - One such response can be to have the unauthenticated VLAN use local DHCP or a remote DHCP relay to the NAC system so that it can give the unauthenticated client an IP address. The DHCP response places the NAC as the unauthenticated devices gateway and DNS server.<br> - Depending on the NAC solution, it is possible that the packets involved during DHCP request and response are captured and analyzed by the NAC solution. <br> - A DHCP fingerprint may be used to authenticate a device. <br> - Commonly, a captive portal is forced on the unauthenticated client and can be used to provide guest internet or logical steps to become authorized. | 5.72 |
| NAC Core Capabilities | NAC solutions authenticate devices various ways<br> - 802.1X Port Authentication (CSC 1.5 + 1.6); <br> -  MAC Address OUI (organizationally unique identifier); <br> - DHCP fingerprint-analyzes DHCP packets of systems <br> - Compliance checks- act as augmentation to authentication; Vulnerability scan; <br> - Intrusion detection system (IDS)-caution is necessary; <br> - Patching/antivirus/user agents/Etc. | 5.73 |
| NAC MAC | - MAC prefix is the first six hexadecimal characters of a MAC address that is associated with the vendor of a specific device. The first six hexadecimal characters are referred to as the OUI, or organizationally unique identifier, used for auth <br> - Since MAC addresses can be spoofed, a post-authentication check, such as a vulnerability scan or SNMP v3 authentication packet, may be used to verify a printer is really a printer. While less common, it is also possible to authorize a device by default but then scan it or attempt to authenticate against it and kick it back off the network should it fail to allow the authentication. | 5.73 |
| quarantine  | Auto Quarintine needs to be done with extreme caution. For example, a NAC solution can be configured to integrate with an IDS or can have an IDS module. This means that alerts could trigger quarantine based on severity. The problem is an attacker could spoof bad traffic to get multiple systems quarantined. Thus, caution is necessary. | 5.73 |
| MAC authentication | is not authentication.; MAC addresses can be spoofed.; Yet validating a client based on MAC is better than not; Beware the perfect solution fallacy.MAC authentication can be combined with 802.1X.; You likely do not use every OUI.; Some MAC addresses are invalid.;  Mainly from MAC tumbling devices or spoofing | 5.73 |
| DHCP Fingerprinting | DHCP request/response can be fingerprinted;   Uses combination of MAC address and option 55;   Option 55 contains the parameter request list.;   How request is performedcan be fingerprinted; What order are options?; What order are they requested?; What is the MAC address? | 5.75 |
| DHCP option 55 | during the DHCP Discover, option 55 contains a list of requested parameters from a DHCP server. The order of this list and the contents of this list tend to be unique to a specific device type, DHCP fingerprinting off option 55 alone is fairly accurate, but the MAC address is also available for use.  | 5.75 |
| DHCP option 6o | is used if present for DHCP fingerprinting w/ NAC, DHCP option 60 is the vendor class identifier often used to identify the operating system in use | 5.75
| Fingerbank | is an online DHCP fingerprint database.; Used by opensource NAC PacketFence. Used by commercial NAC solutions as well....Contains thousands of DHCP fingerprints; Supports manual lookups using free API key | 5.76 | 
| NAC inline | means the NAC solution acts as the gateway for each VLAN. This allows central management and eases network complexity. However, it also introduces a potential point of failure. Inline NAC is only recommended when organizations do not have managed switches with 802.1X support. | 5.77 |
| NAC Out-of-band |  deployments involve reconfiguring network devices to use NAC for port authentication. Typically, port authentication is a combination of 802.1X, MAC authentication, and possibly DHCP fingerprinting. With out-of-band, the NAC system can go offline with minimal impact to the network. | 5.77 |
| NAC inline VS OOB | - Inline **PROs:** Works with any device; Minimal design changes, <br> - Inline **CONs**; Potential failure point; Can slow performance; Requires more hardware;  And high-available server recommended <br> - Out-of-Band **PROs**; Minimal hardware required; Fail open or fail closed; Dynamically change ACLs; Dynamically change VLANs <br> - OOB **CONs**; Requires changes to network infrastructure | 5.78 | 
| NAC's captive portal |  is generally used to handle unauthenticated devices. This means that a device has been plugged in or wirelessly connected that failed to authenticate via 802.1X, MAC authentication, and DHCP fingerprinting. Rather than just failing a device or user, a captive portal can be displayed. <br> - NAC solution has to control traffic, which usually means it hands out DHCP for the unauthenticated VLAN and sets itself to the default gateway and DNS server. <br> Go/Nogo decision <br> Could could also be required on top of normal authentication measures based on conditions. | 5.79 |
| Captive Portal, NAC | Ideally, device passes initial authentication methods; <br> - Captive portal can handle faileddevices or usersDesign is flexible and dynamic; <br> - Terms and conditions onlyGives guest VLAN access; <br> - AD authenticationProvides limited production accessCaptive portal could be forced even with authentications | 5.79 |
| Quarantine, NAC | Authorization should not be static.; NAC can dynamically control access.Conditions that may affect access; Peer-to-peer use;  Or software installed; Abnormal connections; IDS alerts; Endpoint suite alerts| 5.8O | 
| Windows Intune and NAC | If the device isn't enrolled or is enrolled and not compliant its redirected to Intune for enrollment, or for a device compliance check.Users can be allowed or denied access when trying to access corporate Wi-Fi or VPN resources.  <br> Works with Conditional Access. <br> see notes for example and all the vendor integrations | 5.81 |
| NAC Example | - Authorized; Windows authenticates using computer certificate; Printer allowed by MAC; Printer allowed by DHCP <br> - Unauthorized; Personal device fails; Misconfigured box fails; Adversary cloning MAC may succeed | 5.83
| Post-Authentication Checks, NAC | Post-authentication checks are key to dynamic access; <br> -These are key in a Zero Trust architectureChecks can be custom or built-in integrations like:; <br> -Vulnerability scan; Level of risk could change access; <br> -Alternative authentication checks; <br> - SNMPv3, SMB, WMI, SSH, HTTPS; <br> -Port scanning and fingerprinting; <br> -Custom script  Choose your destiny | 5.84 | 
| Automated digital response, NAC | it can be anything. If a business has a low-risk tolerance, the response may be to start cutting off access to critical systems or the internet. If a business has a high-risk tolerance, it may choose to slow down connections simply using QoS. NAC is able to give access and take it away by either moving systems to different VLANs or applying ACLs. Some actions may actually ask for human interaction. For example, if a user were to make abnormal connections, the system may pop up and notify them that unusual activity has been observed and to let them know they are being monitored. By simply  providing awareness, the user may change their behavior. | 5.85 |
| NAC Problems | Organizations are restricted by time and money. <br> - NAC is time-consuming to set up and can be expensive. <br> - As a result, many organizations do not have NAC.Even if deployed, it is likely not deployed everywhere. <br> - Virtual environment does not support NAC well. <br> - Switches in a data center typically do not need NAC.Other forms of device discovery are necessary. | 5.86 |
| 802.1X protocol, DiD| Nac Authentication method, has suffered from serious vulnerabilities, including machine-in-the-middle attacks. Therefore it should not be considered an all-prevent panacea, but rather one more prevention-oriented element in a layered defense-in-depth strategy. | 5.86 |
| Control plane, Authorization |  is core of zero trust; Handles central authentication and global policy; Authorizes requests and authorizes access | 5.89 |
| Data plane, Authorization | handles connections.; Establishes connection mediums; Provides switching and routing; But only if control plane continues to authorize accessIdeally, is one device but for practical reasons is multiple | 5.89 |
|  network access, Zero trust| is a two-step process. The first step is to have access authenticated and authorized via the control plane. The control plane is the centralized control or brain. This brain makes logical decisions about who and what passes authentication and controls ongoing authorization. Its job is to monitor and continuously renew valid connections. However, applying business logic and calculating access authorization is not a fast process. Therefore, the control plane handles logic and provides access to a data plane. The data plane is the switch and network fabric that handles connections. Think of it as traditional switching. | 5.89 |
| continuous verification, Zero Trust | This requires some form of management software to act as a centralized control plane. While it would be ideal to have a single control plane, the truth is an organization is likely to have multiple control planes. For example, an NGFW, reverse web proxy, and identity management solutions can all act as a control plane. Each of these then handles data plane access differently or not at all. The concept of a control plane and data plane is more geared to zero trust architecture of network control devices like NGFWs and reverse proxies. These devices handle logic access controls and then hand connections off to direct network access via hardware. | 5.89 |
| Segmentation Gateway: Micro Core and Perimeter (MCAP) | MCAP creates logical zones of trust and functionality.    Full design should include intra-zone connections.    Heavy allow list approach9o | 5.9O |
| segmentation gateways | The most common way of implementing is to use an NGFW solution as a core router. Since all traffic: <br> whether internal to external, external to internal, as well as internal to internal, <br> must traverse core routing, an NGFW at the core provides central control. Historically, a firewall was never recommended at the core due to latency and performance reasons. Additionally, costs were astronomical. However, NGFW costs have continued to decline, while hardware capabilities and speed have continued to increase.By having centralized control over network access, an organization benefits from: - Simplified management - Increased visibility - Centralized enforcement <br> - Segmentation gateway allows the enforcement of micro core and perimeter (MCAP) trust zones. MCAP is the ability to group users and devices of similar trust levels to enforce access controls. MCAP is not bound by VLAN segmentation. | 5.9O |
| micro core and perimeter trust zones | MCAP is the ability to group users and devices of similar trust levels to enforce access controls. MCAP is not bound by VLAN segmentation. For example, it is possible to have users and devices on the same subnet be split into separate MCAP zones. Logical implementations are easier to establish with traditional segmentation such as VLANs, but a router or firewall acting as a segmentation gateway directly handles routing, so it is able to segment as necessary logically. | 5.9O |
| MCAP trust zones | MCAP is the ability to group users and devices of similar trust levels to enforce access controls. MCAP is not bound by VLAN segmentation. For example, it is possible to have users and devices on the same subnet be split into separate MCAP zones. Logical implementations are easier to establish with traditional segmentation such as VLANs, but a router or firewall acting as a segmentation gateway directly handles routing, so it is able to segment as necessary logically. | 5.9O |
| MCAP groups | should be based on similar application use and data access requirements. Grouping different levels of trust, such as users accessing confidential data with users that access standard data, is not recommended due to the chances of accidentally granting access to confidential data. Depending on the security device in use, an MCAP may only be able to place logical access constraints to network connections traversing a Layer 3 boundary. This means that host-based firewall filters are still necessary to secure Layer 2 connections or for implementing private VLANs. | 5.9O |
| micro core and perimeter groups | should be based on similar application use and data access requirements. Grouping different levels of trust, such as users accessing confidential data with users that access standard data, is not recommended due to the chances of accidentally granting access to confidential data. Depending on the security device in use, an MCAP may only be able to place logical access constraints to network connections traversing a Layer 3 boundary. This means that host-based firewall filters are still necessary to secure Layer 2 connections or for implementing private VLANs. | 5.9O |
| data, assets, applications and services (DAAS) | once interdependencies are understood between DAAS and infrastructure and users, you should put controls in place as close to the protect surface as possible, creating a microperimeter around it. This microperimeter moves with the protect surface wherever it goes. You can create a microperimeter by deploying a segmentation gateway, more commonly known as a next-generation firewall, to ensure only known, allowed traffic, or legitimate applications have access to the protect surface. | 5.92 |
| Segmentation Gateways/NGFWs | Segmentation gateways can use known technologies like NGFW, just implemented in a different way;  - Security hardware today supports core backbone speeds. <br> - NGFWs available with 100 Gb interfaces and well over 100 Gb inspection speeds <br> - SDN or solutions to control switch fabric are maturing. <br> - Reverse proxies and identity management are strong.In many cases, L7 inspection is less important than identity.| 5.92 | 
| MCAP and Network Agent | MCAP and access should be based on network agent; - Developer on corporate desktop has access to source code; - Developer on mobile device does notTrust is calculated by user, device, and other factors | 5.93 |
| Inventory Automation | Key to MCAP grouping is device and user integration; - Users and groups usually sync with Active Directory.; - Device integration requires commercial add-on solutions.; - Or simple scripts that hook REST APIs or SSHNetwork agent needs real-time application of user + device| 5.94 |
| Real-Time Device Inventory | NAC and VPN solutions require authentication before providing network access. <br> - Post-authentication task can feed segmentation gateway;  Such as running script to update address objects <br> - Can be achieved by using centralized logging;  Send logs to security information and event management (SIEM);  Use SIEM to react to NAC or VPN logs in near real time. | 5.95 |
| Segmentation Gateway - Centralized Protection | Internal firewalls provide centralized access controls.. Helps push filtering as close to source as possible. Endpoint firewall is granular but deep within network <br>- Filter on ports and application; Filter on user and device; Filter on time restrictions  | 5.96 | | Internal firewalls provide centralized access controls.. Helps push filtering as close to source as possible. Endpoint firewall is granular but deep within network <br>- Filter on ports and application; Filter on user and device; Filter on time restrictions  | 5.96 |
| Centralized controls, Segmentation Gateway | help achieve significant filtering against a network agent as well as limit access to allow listed and known applications. Another capability a segmentation gateway supports is applying time constraints against authorization rules. | 5.96 |
| Temporal Abnormal Condition | Access outside normal user window...Should be monitored and reacted to (Dynamic Auth) | 5.97 |
| Geographical Abnormal Condition | Access from different location...Should be monitored and reacted to (Dynamic Auth) | 5.97 |
| Behavioral Abnormal Condition | Access to resource user does not normally use...Should be monitored and reacted to (Dynamic Auth) | 5.97 |
| Frequency Abnormal Condition | Last access or volume of device/user useOr number of requests over time...Should be monitored and reacted to (Dynamic Auth) | 5.97 |
| Dynamic Authorization | Abnormal conditions should be monitored and reacted to. <br> Temporal: Access outside normal user wind <br> Geographical: Access from different locati <br> Behavioral: Access to resource user does not normally u <br> Frequency: Last access or volume of device/user use; Or number of requests over time <br> -Deviation from norm may dictate additional checks:  Multifactor authentication,  Approval from manager or administrator | 5.97 |
| Dynamic Authorization with Conditional Access and RBAC |  - Dynamic authorization is a ZT capability, requiring various PDPs, and PEPs to be able to apply it across people, devices, networks, workloads and data. <br> - Conditional Access is Microsofts implementation of ZT policy engine, taking signals from various sources into account when enforcing policy decisions. <br> - Goes together with MFA (identity), and SSO (authorization) based on Role-Based Access (RBAC) | 5.98 |
| Microsoft Conditional Access, PDP |  can serve as a policy decision point to review signals and evaluate whether access to a resource should be allowed or denied. The request is then handed to a policy enforcement point to take the appropriate action. <br> -Microsoft Conditional Access goes hand in hand with MFA solutions that integrate with it. If you are using Entra ID to provide federation for web applications, its recommended to enable Conditional Access for all SSO apps, and to disable all legacy protocols to avoid conditional access from being bypassed. Microsoft can provide additional signals to Conditional Access, including those coming from the Identity Protection product, Windows Defender and Intune for device posture. | 5.98 |
| Segmentation gateway | provides centralized: <br>-Network agent (user + device) access controls <br>-Time constraints and limitations <br>-Data-centric port and application controls <br>-MCAP trust zoningNGFW can be deployed as a segmentation gateway. <br>-Capabilities increasing and hardware cost decreasing <br>-Able to automate via robust API supportThe concept of the segmentation gateway in modern Zero Trust apply to identities, devices, networks, workloads, and data | 5.99 |
| SIEM | What is a SIEM used for?<br> - Centralized log collection<br> - Advanced alerting<br> - Systems automation<br> - Analysis system<br> - Compliance repository<br> - Big data analytics platform<br> - Threat intelligence | 5.102 |
| Log Collector,  SEIM |   While not directly part of the SIEM, log collection is a critical piece of the overall SIEM architecture. This can be done many different ways, such as through the use of agents, agentless log collection, and scripts. | 5.103 |
| Log Aggregator,  SEIM |   This acts as central collection points of logs. It ingests raw logs and have the capability to parse and add context to the log. A log aggregator can also be used to generate alerts early on in log processing. | 5.103 |
| Log Broker,  SEIM |   A broker is a temporary storage location for logs. Logs go into the broker and are stored until an aggregator can pull them out. Many times, this results in two sets of log aggregators: one to accept logs and put them into a log broker and one to pull logs from a log broker and parse them. A brokers primary purpose is providing redundancy and the ability to handle fluctuations in the log collection process. If processing gets backed up, the logs will not be dropped. They simply stay with the broker until processing catches back up. | 5.103 |
| Storage,  SEIM |  logs are finished being processed, they end up being stored in a backend storage node. The storage node is responsible for storing logs on disks and retrieval of those logs. How the storage system handles logs varies from solution to solution. | 5.103 |
| Search/Report,  SEIM |   A report node is typically used to search and report on logs that are sitting in the storage node(s). | 5.103 |
| Alert Engine,  SEIM |   An alert engine is used to search for logs in the storage nodes and trigger alerts based on defined workflows. | 5.103 |
| Log Inspection, SEIM | All system and network access needs to be verified.; <br> - Ad hoc reporting is inefficient and difficult to do.; <br> - Central log collection and scripting is low cost.; <br> -  But also suffers from major deficiencies<br> - SIEM log collection and analysis is recommended.; <br> - Focus should be on key log sources; <br> - And inspecting them for expected network and system use; <br> - Use log enrichment to enhance analysis. | 5.104 |
| Log Enrichment | slide shows the enrichment of a dns query to google.com.  Adds Query, Subdomain, Parent and registered domain, creation time, tags, geo.as, freq. score, and parent domain length | 5.105 |
| Data lakes and data warehouses, Cloud | offer a number of powerful features for data analytics, such as machine learning and artificial intelligence. Data analytics methods and serverless queries like Google Dataproc or AWS Athena can be very helpful for select use cases. For example, they can be used to identify anomalies in the data, to perform correlation analysis, and to create dashboards and reports. | 5.106 |
| SIEM, Cloud | - Some are exporting data from their traditional (aka. compliance) SIEM to cloud based storage like S3 buckets or data lakes like Databricks.<br> - Data analytics methods and serverless queries like Google Dataproc or AWS Athena can help build detection cases. <br> - May require some expertise and functionality will be reduced compared to full blown SIEM, but it can help in threat hunting, building dashboards and other anomaly detection engineering efforts. | 5.106 |
| Log Collection | Logs must be collected prior to inspection.Typically done with:; Log agent- Requires software; Agentless- Requires credentials and scanning of remote systemsNetwork devices often use syslog (NGFW, Proxy, DLP) <br> Other metods exist, such as SNMP traps or APIs.| 5.11O |
| Syslog | Syslog is the most common network protocol for sending logs on the network. <br> - Also, a built-in daemon for network devices and UnixDefault is UDP on port 514 <br> - Some systems support TCP but uncommonRFCs support TLS encryption.1 <br> - Yet most systems only support syslog over UDP without encryption. | 5.111 |
| RFC 3164 |  BSD syslog- States the maximum packet size for syslog over UDP is 1024 bytes. Even though syslog is used on non-BSD systems, many follow suit and will either drop or truncate a log packet over 1024 bytes. The reasoning behind this size limit is that UDP does not keep track of packets and, therefore, the loss of a single packet when using fragmentation would garble a message. Due to this and the fact that the standard MTU size is 1500 bytes, 1024 bytes was selected.For TCP, this size is often limited to 4096 bytes. | 5.111,113 |
| RFC 5424 | newer than RFC 3164, based on the syslog protocol | 5.111 |
| Syslog Message Limitations Size | Inconsistent; Message formats can vary dramatically; Requires additional parsing <br> - Majority of systems are limited in message size; Syslog over UDP often limited to 1024 bytes (RFC 3164);  Fragmentation typically not used with UDP;  Standard MTU is usually 1500 bytes.; Syslog over TCP often limited to 4096 bytesS | 5.113 |
| Windows log size | can be over 30 K in size, and yet, many agents transmit Windows event logs over syslog | 5.113 |
| Windows Events | Microsoft events are stored in proprietary binary format.<br> - Requires Windows Event Viewer or special agent to read; New format is still binary but is XML based<br> - Supports up to 32,766 bytes (syslog UDP is 1,024)<br> - Allows for custom parameters in message sectionEvents are broken up by:<br> - Channels -  A group of logs such as Security or System<br> - Event IDs -  Unique IDs to filter on | 5.114 |
| XML Logs | - Starting with Windows Vista, Windows events are XML based. This means fields are stored in parameters rather than having one large message with a bunch of data. This makes event fields specific and readable <br> - The fact that it is XML means that the parameters are defined and extractable with the right agent.  Unfortunately, many native SIEM agents will only pull fields that they want to collect. This means you may only have 50-100 Windows fields when, in fact, there can be more than a thousand in a large environment. | 5.116 |
| nxlog and fluentd | Log Agent, Suupports many features | 5.117 |
| fluentd and nxlog | Log Agent, Suupports many features | 5.117 |
| Auto-parsing, Log Agent feature | Automatic parsing of CEF, CSV, XML, KV, LEEF, JSON, GELF, W3C, Syslog, etc. | 5.117 |
| Data diode support, Log Agent feature | One-way communication of log traffic | 5.117 |
| Pre-parsing, Log Agent feature | Filtering of logs at the endpoint system. | 5.117 |
| Event rate controls, Log Agent feature | Can limit the number of logs sent to control bursts | 5.117 |
| Log rotation, Log Agent feature |Scheduled purges/moving to archive of local logs | 5.117 |
| Log buffering, Log Agent feature | In the event that logs are not being accepted when sent, the agent can locally buffer in memory or disk up to a certain size and then resend when communication is reestablished. | 5.117 |
| Server mode, Log Agent feature | Some agents can also act as a collection server. This can be used to create log relays. For example, if you had a low bandwidth site, you could send all logs to an agent in server mode and have that agent send logs on in a highly compressed fashion and you could also apply pre-filtering prior to sending. | 5.117 |
| Multiple destinations, Log Agent feature | Logs can be delivered to multiple destinations that can support various protocols (TCP, UDP, etc.). | 5.117 |
| Encryption, Log Agent feature | Logs can be sent over encrypted channels such as TLS. | 5.117 |
| Log integrity, Log Agent feature | Logs can be sent with hashes or checksums to verify the integrity of the log in transit.  | 5.117 |
| Priority routing, Log Agent feature | Agent can treat certain logs or events as high priority. These receive special treatment such as being routed first. This also can be used in cases where if many logs are getting generated and logs are starting to drop, priority logs are not among those to be dropped. | 5.117 |
| File monitoring, Log Agent feature | File integrity monitoring of files or directories | 5.117 |
| Registry monitoring, Log Agent feature | Registry integrity monitoring of registry keys | 5.117 |
| NetFlow ingestion , Log Agent feature |  Support for accepting NetFlow and turning it into a log or event | 5.117 |
| Alerting, Log Agent feature | Alerts can be triggered based on conditions such as seeing certain patterns or based on more advanced conditions, such as seeing 500 failed logon events. | 5.117 |
| Remote administration, Log Agent feature | Some agents require configuration files be pushed through asset management software. Others provide their own central management for remote administration. | 5.117 |
| Message conversion , Log Agent feature |  Converts log message from one type to another. For example, the original message could be syslog and then converted into JSON. | 5.117 |
| Internationalization, Log Agent Feature | Some agents can automatically detect character sets as well as convert to others. | 5.118 |
| Cloud API Integration, Log Agent Feature |  Pulls logs from mainstream cloud providers such as Amazon and Google through API calls | 5.118 |
| Windows Event Forward collection, Log Agent Feature | Some log agents have the capability to act as a Windows Event Collector server. | 5.118 |
| Syslog Agents and Windows | Windows events may not fit within the constraints of syslog.<br> - Large events may get truncated.<br> - Or will be chopped upSyslog-based agents may separate logs into smaller pieces.<br> - Newline character used to break up sections<br> - Last piece without newline distinguishes end of logPutting the pieces back together adds overhead.<br> - As does monitoring for newlines | 5.119 |
| Syslog Agents and Windows | Depending on the agent or transport mechanism, Windows logs may be truncated or dropped. For example, the log above is 1,652 characters, which means it is 1,652 bytes, not including any header information. If sent over syslog using UDP, it may only store two-thirds of the message. | 5.119 |
| Agentless Log Collection | Agentless involves a central server to collect logs; - Server authenticates to systems over WMI or SSH; <br> -Logs are collected in batches.; <br> -Requires admin privileges or additional rights; <br> -Windows 2008+ can use the Event Log Readers group. Main benefit is no additional software; <br> -Do not have to maintain and upgrade agent; <br> -Quicker to deploy and manage | 5.12O | 
| Logs, Traditional vs. Network Extraction | Traditional-Multiple collection points, Network Extraction-Single collection point | 5.121 |
| Audit Policies | - Log collection is dependent on proper audit policies.; <br> - Logs must be generated before being collected.; <br> - Default logging settings are insufficient.; <br> - Windows utilizes audit policies to enable logging.; <br> - Linux requires configuration file changes.; <br> - Both support custom logs such as with PowerShell.; <br> - Or third-party programs to add additional logging| 5.124 | 
| secpol.msc | in windows, audit policy settings can be accessed through the Local Security Policy snap-in (secpol.msc) on the local computer or by using Group Policy. | 5.124 |
| Account Management events | Used to track changes to groups, users, and computers; Needed to monitor key groups for modifications; Such as new members added to Domain AdminsPowerful when combined with change control system | 5.125 |
| Audit Application Group Management | Monitors changes to application groups. Application groups are used to tie roles using Windows Authorization Manager. | 5.125 |
| Audit Computer Account Management | Monitors changes to computer accounts. | 5.125 |
| Audit Distribution Group Management | Monitors changes to Active Directory distribution groups. While this can record details about groups being modified such as Domain Admins, it is not needed. The Audit Security Group Management records more information that is helpful and specific. | 5.125 |
| Audit Other Account Management Events | Monitors special changes such as a password hash of a user account being accessed or changes to the password policy or lockout policy. | 5.125 |
| Audit Security Group Management | Monitors changes to standard security groups. | 5.125 |
| Audit User Account Management | Monitors changes to user accounts. | 5.125 |
| Object access  | controls logging for quite a few things. If you wish to audit files, registry keys, or network shares, you must enable the auditing capability first. For example, after turning on Audit File System, it grants Windows the ability to audit things like files or folders being accessed but only if an ACL is placed on them telling what to audit. In other words, the ACL has no impact on auditing, but the SACL does. In the past, there was a wide misconception that enabling this would generate an event for every file accessed.  This audit policy also controls things such as Windows Firewall logging to a log channel and file access on removable drives. In Active Directory, many things are considered objects (users, groups, files, folders, registry keys, etc.). This policy even controls certificate-related events. | 5.126 |
| Audit File System | it grants Windows the ability to audit things like files or folders being accessed but only if an ACL is placed on them telling what to audit. In other words, the ACL has no impact on auditing, but the SACL does. <br> -also controls things such as Windows Firewall logging to a log channel and file access on removable drives. In Active Directory, many things are considered objects (users, groups, files, folders, registry keys, etc.). This policy even controls certificate-related events. | 5.126 |
| auditing process creation | include command line parameters, enable *Audit Process Creation* but also enable the policy Include command line in process creation events located at Computer Configuration -> Policies -> Administrative Templates -> System -> Audit Process Creation. | 5.127 | 
| Sysmon | Free download from Windows Sysinternals; Written by Mark Russinovich and Thomas Garnier; Runs as a Windows system service and device driver;<br> - Monitors:;  Processes;  Network connections;  Driver and DLL loading;  Raw disk access;  Modifications of file creation times;  Process access;  DNS <br> - Provides process hashes and parent processes for analysis <br> - Sysmon utilizes built-in Windows API calls and ETW tracing to generate logs. This allows for minimal performance overhead. <br> -allows fine-grained filtering on what to log <br> - Sysmon is built for both desktops and servers. It can be deployed to Windows 7 and newer as well as Server 2012 and newer operating systems | 5.128 |
| Sysmon Configuration | Granular logging available; Uses XML config; Can include or exclude on:, -Path, -Process/image, -Digital signature, -Integrity level | 5.13o |
| Sysmon commands | sysmon.exe --help, sysmon.exe -? config | 5.13o |
| auditd | Provides a customizable Linux Audit system.  <br> - Monitors: File Access, System calls, Program execution, File changes, Security events (such as failed logins), Network access <br> - Granular monitoring allows advanced use cases   Also, adds complexity and performance overhead | 5.131 |
| Audit Example | PID is process ID of executable, PPID is for parent process <br> - UID is user ID of user <br> - AUID is the audit user ID (tracks actions against logon even if user changes with su or sudo) | 5.132 |
| audit rules |  Auditd allows for extremely granular monitoring. As a result, it is usually best to plan exactly what needs logging before writing the auditing rules. A general rule of thumb is to try and log only what you intend to actually look at. In the case of auditd, logging everything can have adverse effects on system performance.The audit.rules file is composed of three types of rules: control rules, ilesystem rules, and system call rules. Control rules are used to define configuration settings for the audit system.  | 5.133| 
| audit.rules, control |  the first rule is -D, which clears out all rules at the beginning of a configuration file load. Then it sets the backlog size limit using -b. In this case, the buffer is set to 320 logs. The limit is likely too small for even moderately accessed systems and may need to be increased to 1024 or higher. The higher this is set, the more memory is consumed to handle the buffer. To monitor if your buffer is set high enough, run the command ***auditctl -s*** and look at the field called lost. If it is not set to zero, then some logs have been lost, and you may need to increase the buffer size. | 5.133 |
| aduit.rules, System call rules | System call rules monitor system calls from processes or users. In this slide, the first custom rule is an example of a system call rule. <br> It takes place after the -D and -b control rules. -a exit,always -F arch=b64 -S sethostname -S setdomainname -k system-locale-a stands for append rule and is applied when monitoring system calls. If -A was used instead of a, it would append the rule at the top of the rule list instead of the bottom. Immediately following -a or -A should be one of four possible options: task, exit, user, or exclude. In almost all cases, exit will be used. -F arch=b64 refers to the 32-bit or 64-bit architecture. In this case, the syscall for 64-bit calls is being monitored. Note that in some cases you may need to monitor both 32-bit and 64-bit syscalls on a 64-bit Linux system. | 5.133 |
| audit.rules, File monitor rules| The last two rules specified in this slide are examples of file monitor rules. They are as follows: -w /etc/passwd -p wa -k passwdrule -w /sbin/ifconfig -p -x -k ifconfigrule-w specifies that the rule is a watch rule. The file or directory following -w specifies what is being watched.-p specifies the permissions that are logged. The possible options are r (read), w (write), x (execute), and a (attribute change). In the first example, -p wa is used to monitor writes and attribute changes to the /etc/passwd file. This would log when new users are added to the system. The next example of -p x is used to monitor each time /sbin/ifconfig is executed. Both examples use -k to give the rules names that are recorded in the logs they generate | 5.134 |
| Detection Engineering | is the process of researching threats and then building and tuning tools that find them.  We need to be able to describe what we want to detect in a structured way so various tools can hunt and find evil. | 5.137 |
| Sigma Generic Signatures |  -Written by Florian Roth and Thomas Patzke"To logs, what Snort is to network traffic and YARA is to files" <br> -High-level generic language for analytics  Enables analytics reuse and sharing across orgs; MISP compatible - share and store aligned with threat intel <br> -Decouples rule logic from SIEM vendor and field names - Eliminates SIEM tribal knowledge,  Works across SIEM and non-SIEM tools | 5.138 |
| Sigma how it Works | To make Sigma rules work with a SIEM, they must be converted using sigma-cli. The process looks as follows: <br> 1.  Write a rule in Sigma format. <br> 2.  Create a file mapping generic field names to field names within a given SIEM platform. <br> 3.  Use sigma-cli to convert from Sigma format to a specific SIEM product rule format.The process is simple and can be automated with basic scripting skills. | 5.139 | 
| SIGMA, Conversion of Signatures to Alert Queries | slide shows workflow | 5.14O |
| SIGMA Currently Supported Outputs|  SIEM/XDR: -Splunk -QRadar -Cortex XDR -Elasticsearch  -Sentinel One -Carbon Black, etc <br> Endpoint Queries:     Windows Defender Advanced Threat Protection;   PowerShell;   grep | 5.141 |
| Sigma Rule Format | Plaintext YAML files. **Easy schema**: <br> 1.  Metadata; Title, status, description, references, tags, etc. <br> 2. Log source; What type, brand, and service is the log from? <br> 3. Detection; List of selectors<br> 4. Condition; Logic for selector matching | 5.142 |
| Sigma - Title, Metadata, and Log Source | Sigma rules are written in YAML format. The sigma rule in this slide is an example showing that each rule has a title, status, and log source, as well as information about the rule, such as a description and tags. The format allows for ease of readability and customization. | 5.143 |
| SIGMA - Log Source Section | Optional Classifiers: <br> category: proxy, firewall, AV, IDS- For all logs of a group of products <br> product: Squid, pfSense, Symantec, Snort, Windows- For all log outputs of one product  <br> service: SSH, DNS, DHCP- For a subset of a products logs-sshd, named... <br> description: Additional detail on log source, configs | 5.144 | 
| SIGMA - Log Source Section | Optional Classifiers- <br> **category**: proxy, firewall, AV, IDS- For all logs of a group of products <br> **product**: Squid, pfSense, Symantec, Snort, Windows- For all log outputs of one product  <br> **service**: SSH, DNS, DHCP- For a subset of a products logs-sshd, named... <br> **description**: Additional detail on log source, configs | 5.144 | 
| Sigma Detection and Conditions | **Condition:** Logic for rule matching; **Detection:** Object containing items of interest; [field name] - referenced in the condition  | 5.145 |
| Sigconverter.io | - The most critical aspect of Sigma rules is the ease of operationalizing them. ; <br> -sigconverter.io, a new web-based converter for Sigma rules that uses pySigma; and the legacy sigmac, since it supports backend languages that aren't yet supported by pySigma. | 5.146 |
| pySigma |  is a replacement for sigmac and other tools in the legacy Sigma toolchain, with a much cleaner design. | 5.146 | 
| sigma-cli | command-line tool as a front-end to pySigma, a Python library that parses and converts Sigma rules into queries.  | 5.146 |
| Sigma2attack | Command line tool to generate MITRE heatmap from Sigma; Export heatmap.json; Import into Navigator; Score based onvolume of rules | 5.147 |
| Anomaly Identification vs. Real-Time Alerts | Some MITRE techniques create large quantities of false positives as real-time alerts.  Those signatures work well for threat hunting.A | 5.148 |
| Red Herring | In literature the red herring is a deliberate diversion of attention with the intention of trying to abandon the original argument. <br> - The concept can be applied as a defensive posture.Red herring defenses beneficial in conjunction with an assumption of compromise; <br> - Redirect adversaries to avoid compromise; <br> - Change behavior of automated and malicious tools; <br> - Increase detection while slowing down attacks | 5.152 |
| MITRE Engage and ATT&CK Mappings | - MITRE has released MITRE Engage, a framework for discussing and planning adversary engagement, deception, and denial activities. <br> - Engage is informed by adversary behavior observed in the real world and is intended to drive strategic cyber outcomes. <br> - MITRE Engage maps the various Engagement Activities to ATT&CK®, to ensure that each activity in Engage is driven by observed adversary behavior. | 5.153 |
| Adversary Vulnerabilities | are the weaknesses an adversary unintentionally exposes when they engage in a particular behavior. The defender has an opportunity to impact the adversary by taking advantage of such a vulnerability. We have chosen to include Adversary Vulnerabilities in place of Opportunity Spaces to make adversary behavior a focal point of Engage. We feel that this framing helps the defender keep the adversary, and the adversary's behavior, at the center of every operation. | 5.153 | 
| active defense | The employment of limited offensive action and counterattacks to deny a contested area or position to the enemy. | 5.153 |
| MITRE Engage | is a framework for discussing and planning adversary engagement, deception, and denial activities. Engage is informed by adversary behavior observed in the real world and is intended to drive strategic cyber outcomes. Engage was created to help the private sector, government, and vendor communities to plan and execute the use of adversary engagement strategies and technologies. | 5.153 |
| Service Banners | Many applications identify their software and version number upon connection. <br> - Attackers and malware use information for exploitation  <br> - Possible to change version, application, or OS identification; May be sufficient to break automated attack tools and scans; Implemented at the local server or with a reverse proxy <br> -     Alternative is to hide or limit informationMay break automated attacks; But less effective | 5.154 |
| Apache version | an attacker can automatically or manually identify possible exploits specific to the version of Apache. To better protect the Apache web service, the configuration can be changed to ProductOnly. This setting will present only Apache as the banner. No version numbers or additional information are presented | 5.155 |
| Apache ServerTokens | On older Apache services, the setting defaulted to Full. As a result, all HTTP responses from the Apache server would include the full Apache versions, operating system, and any additional frameworks such as PHP with a specific version number. Newer Apache services default to OS, which includes the exact Apache version in use and the high-level operating system in use. This configuration may either be in httpd.conf or in newer operating systems and can be found in /etc/apache2/conf-enabled/security | 5.155 |
| Service Banners, Changing | The alternative is to rewrite or modify the service banner.;  Either done with local software or with reverse proxy;  A reverse proxy has extra benefits. <br> - The real banner can be made visible to select systems/users. <br> - Centralized control and managementTools often target system using service information;  Means attack is unlikely to succeed;  And provides early warning of being targetedC | 5.156 |
| rewriting content, Service Banners | rewritting on the fly with a reverse proxy also allows rewriting other content that attackers make use of, such as** X-Powered-By**. The X-Powered-By field contains the programming language in use by a web service. Again, the information provides an attacker directly what they need to target. A similar option is available for IIS using URL Rewrite | 5.156
| X-Powered-By | field contains the programming language in use by a web service. Again, the information provides an attacker directly what they need to target. A similar option is available for IIS using URL Rewrite | 5.156 | 
| Service Banner - Detection Capabilities | Meaning of detection based on attack source and destination;<br> **External-** Early detection of external threat; Expected true positives (may occur so much as to be noise);<br> **Internal-** Early detection of insider threat; Low false positives and true positives (high fidelity alert) | 5.157 | 
| User-Agents Proxy modification | can be used to protect clients. <br> - User-Agent describes web client application. <br> - Malware uses User-Agent to identify and deliver malicious payloads. <br> - Example: Metasploit Browser Autopwn <br> - Organization may use Google Chrome, but User-Agent can be rewritten as Internet Explorer <br> - Can be applied to any web traffic <br> - Or possibly only to non-allow-listed websites | 5.158 |
| Honeypot | A honeypot is a system designed only to be attacked and monitored.; **High interaction** honeypots use real services.; Often use vulnerable services and hope to be compromised for research; **Low interaction** honeypots emulate services.; Useful as early detection devices |  5.16o | 
| virtual honeypot | also coined as low-interaction honeypots, are software-based programs that emulate connections. For instance, an attacker could port scan a virtual honeypot, and the software would emulate real services to make it look real. These are designed for low interaction, so attackers can compromise the systems and attack others. The reason for some interaction rather than none is that it slows down attackers from targeting real systems while providing early detection. | 5.16O |
| Low Interaction Honeypots | Multiple community projects offer easy to set up honeypotsOften support multiple low interaction servicesAnd centralized management with web management <br> Two modern honeypot frameworks include: <br> **1.  Active Defense Harbinger Distribution (ADHD)** All the best active defense tools in an updated Linux distro <br> 2. T-Pot2 - 20+ honeypots and countless visualizations using Elastic | 5.161 |
| Active Defense Harbinger Distribution (ADHD) | Low interaction honey pot; All the best active defense tools in an updated Linux distro | 5.161 |
| T-Pot | - 20+ honeypots and countless visualizations using Elastic | 5.161 |
| Honeypots | An internal-only honeypot should see more than scans.; Records should pointto honeypot;  Common DNS records;  OS shortcut links;  Web linksUnder normal conditions, a honeypot should not be hit.; Now attacker scans or enumeration identifies them. | 5.162 |
| Honeytokens | Fake objects or content is helpful for identifying unauthorized activity. <br> - *Fake objects or content is referred to as a Honeytoken.; Sometimes referred to as a Canarytoken* <br> - Implementation requires data placement and logging.; Credit card Excel sheet with file auditing; Web bug links with web server's logs; SQL record with stored procedure logging; Fake access credentials in a git repo | 5.163 |
| File Auditing | Automated scripts/malware often used to find patterns <br> - TOP SECRET, social security #, credit card #, etc. <br> - Operate by enumerating and reading through files <br> - Often ignores hidden folders; Enable file auditing using Windows GPO1or Linux auditd. | 5.164 |
| Security Access Token (SAT) Honeytokens | Lateral movement usually from credential compromise; <br> - Security access tokens (SAT) stolen from memory and reused, Mimikatz is common attack tool to steal credentials <br> Possible to place SAT honeytoken on all systems; Simple method is to run logon script via group policy; MimikatzHoneyToken project available on GitHub2; Or open-source agent/server system available; DCEPT project provide easy-to-rollout agents and server; Creates honeytoken per system to pinpoint compromised asset | 5.165 |
| MimikatzHoneyToken  | project available on GitHub2; Or open-source agent/server system available; | 5.165 |
| DCEPT | DCEPT is an open-source agent/server solution. A server is deployed at a central location, and then a custom agent is deployed to all systems. Each agent obtains a honeytoken credential from a DCEPT generation server. This occurs once a day by default and is used to identify which system is compromised uniquely. A DCEPT sniffer runs alongside the DCEPT server looking for honeytoken credentials. If a honeytoken is identified, the server looks up the credential used in the database to identify the specific asset that is compromised. | 5.165 | 
| net group "Domain Adims" /domain | attacker recon possibly, event id 4662  | 5.166 |
| Auditing Attacker Reconnaissance  | Certain insider threat activitiesare common. Such as: **crawling folders/files** Or finding who is in the** domainadministrators group**;  Tactical auditing | 5.166 |
| CanaryTokens.org | thinkst offers a free token service at canarytokens.org.;<br> - Thinkst also provides commercial honeypot solutions. GUI wizards provides walkthrough;<br> - Takes minutes to deploy a token;<br> - Wizard supports unique monitors:; Detect website being cloned; Alert if AWS key or Azure Service Principal certificate is used; Identify if custom binary executed | 5.167 | 
| SQL honeytoken | generates a SQL query that creates a stored procedure and trigger.  | 5.167 | 
| Windows folder honeytoken | generates a *desktop.ini* file that is used when a folder is browsed. | 5.167 | 
| cloned website honeytoken | uses JavaScript to identify a site has been cloned. It does so by using JavaScript that does nothing if the domain of the site being loaded matches the JavaScript. If the site is cloned and accessed without removing the JavaScript, then the domain will not match, causing the JavaScript to phone home. | 5.167 |
| HALO (Honeytokens against Leveraging OSINT) | Fake users can be created publicly to combat recon.; Could be just in hidden metadata and/or key public sitesExample: Peter Parker (pparker@sec530.com); On LinkedIn, Facebook, Adobe, PGP, GitHub, etc.; Likely to be picked up during OSINT; May eventually make compromised account lists; Takes minimal time to set up can get fairly elaborateActivity from this account is malicious and provides context. | 5.168 |